{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BackTranslation\n",
      "  Downloading BackTranslation-0.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting googletrans==4.0.0rc1 (from BackTranslation)\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from BackTranslation) (3.8.1)\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation) (2024.6.2)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from nltk->BackTranslation) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from nltk->BackTranslation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from nltk->BackTranslation) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from nltk->BackTranslation) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from click->nltk->BackTranslation) (0.4.6)\n",
      "Downloading BackTranslation-0.3.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.1/55.1 kB ? eta 0:00:00\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.4/133.4 kB ? eta 0:00:00\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB ? eta 0:00:00\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.0/65.0 kB ? eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.0/1.3 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 27.5 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB ? eta 0:00:00\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17458 sha256=f4b6900e1cd72ece1a570c2bf37f674dfe8640b26b0cfeee17315605fc76f2f6\n",
      "  Stored in directory: c:\\users\\danny tapp\\appdata\\local\\pip\\cache\\wheels\\95\\0f\\04\\b17a72024b56a60e499ce1a6313d283ed5ba332407155bee03\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans, BackTranslation\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "Successfully installed BackTranslation-0.3.1 chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'c:\\Users\\Danny Tapp\\anaconda3\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install BackTranslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BackTranslation import BackTranslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = BackTranslation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'My favorite lunch currently is lemon pepper wings with a side of carrots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'russian': 'ru'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = BackTranslation()\n",
    "trans.searchLanguage('Russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spanish': 'es'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.searchLanguage('Spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'japanese': 'ja'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.searchLanguage('Japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite lunch is currently - lemon pepper wings from carrots\n"
     ]
    }
   ],
   "source": [
    "result = trans.translate(sentence, src='en', tmp='ru')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite lunch is currently lemon pepper wings with one side of carrots\n"
     ]
    }
   ],
   "source": [
    "result = trans.translate(sentence,src='en',tmp='es')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite lunch is the lemon pepper wings on the side of the carrot\n"
     ]
    }
   ],
   "source": [
    "result = trans.translate(sentence,src='en',tmp='ja')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\danny tapp\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://stackoverflow.com/questions/64848653/python-datetime-module-and-getting-current-time\"\n",
    "response = requests.get(url,stream=True)\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm a beginner in Python and I want to make a simple project to say how much time is left until Christmas.\n",
      "First I had a problem with the current time:\n",
      "import datetime\n",
      "now = datetime.now()\n",
      "print(now)`\n",
      "\n",
      "and the error said module 'datetime' has no attribute 'now'\n",
      "Than I fixed it by doing from datetime import datetime\n",
      "but than the calculation for the date created an error\n",
      "The code:\n",
      "from datetime import datetime\n",
      "xmas = datetime.date(2020, 12, 25) - datetime.date.today()\n",
      "now = datetime.now()\n",
      "print(now)\n",
      "\n",
      "And the error was: Exception has occurred: TypeError descriptor 'date' requires a 'datetime.datetime' object but received a 'int'\n",
      "Please help me.\n",
      "Have a nice day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_tag = soup.find('div',{'class':'s-prose js-post-body'})\n",
    "question = question_tag.get_text()\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The datetime class is a little confusing to import because it's in a module that's also called datetime.  When you do from datetime import datetime you're importing the class datetime into the current scope and can just do datetime.now().  If you just do import datetime you're importing the module datetime and so the class is datetime.datetime, making the now method datetime.datetime.now().  Clear as mud?  :)\n",
      "Further adding to the confusion, the datetime module has a date class, and the datetime class has a date method.  You're mixing the two up in your code, calling the date method of the datetime class when you mean to be constructing a date object.  Since you did from datetime import datetime, you did not import the datetime.date class at all.\n",
      "Anyway, here's how to fix it:\n",
      "import datetime\n",
      "\n",
      "xmas = datetime.date(2020, 12, 25) - datetime.date.today()\n",
      "now = datetime.datetime.now()\n",
      "print(now)\n",
      "\n",
      "Note that in this code, xmas is a datetime.timedelta object, and now is a datetime.datetime object.\n",
      "You could also do:\n",
      "from datetime import date, datetime\n",
      "\n",
      "xmas = date(2020, 12, 25) - date.today()\n",
      "now = datetime.now()\n",
      "print(now)\n",
      "\n",
      "Hopefully seeing the two examples side by side helps clarify the module vs class thing.  It's all about different levels of indirection -- in the first example the import statement brings in the whole module, and your code needs to specify which classes to pull out of it.  In the second example, the from ... import statement pulls those two classes out of the module as part of the import, and so the code can access them by those names directly.  Since the names are all so similar, you can't rely on the name to know what kind of thing you're accessing unless you really understand what exactly the import statement did.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share\n",
      "\n",
      "\n",
      "Improve this answer\n",
      "\n",
      "\n",
      "\n",
      "                        Follow\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "edited Nov 15, 2020 at 19:18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            answered Nov 15, 2020 at 19:13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SamwiseSamwise\n",
      "\n",
      "71.5k33 gold badges3535 silver badges5050 bronze badges\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "can I ask for one more thing? Its how to calculate the time until chrismas like I did for the date. Because I'm having problems with it\n",
      "\n",
      "– Josh Brown90\n",
      "\n",
      "\n",
      "Commented\n",
      "Nov 15, 2020 at 19:32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time_till_xmas = datetime(2020, 12, 25) - datetime.now()\n",
      "\n",
      "– Samwise\n",
      "\n",
      "\n",
      "Commented\n",
      "Nov 15, 2020 at 20:27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Add a comment\n",
      " | \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_tag = soup.find('div',{'class':'answer js-answer accepted-answer js-accepted-answer'})\n",
    "best_answer = answer_tag.get_text()\n",
    "print(best_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx\"\n",
    "local_filename = \"COVID19_Twitter_Dataset.xlsx\"\n",
    "response = requests.get(file_url, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (local_filename,'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/232.6 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 133.1/232.6 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Simple PDF File \n",
      " This is a small demonstration .pdf file - \n",
      " just for use in the Virtual Mechanics tutorials. More text. And more \n",
      " text. And more text. And more text. And more text. \n",
      " And more text. And more text. And more text. And more text. And more \n",
      " text. And more text. Boring, zzzzz. And more text. And more text. And \n",
      " more text. And more text. And more text. And more text. And more text. \n",
      " And more text. And more text. \n",
      " And more text. And more text. And more text. And more text. And more \n",
      " text. And more text. And more text. Even more. Continued on page 2 ...\n",
      " Simple PDF File 2 \n",
      " ...continued from page 1. Yet more text. And more text. And more text. \n",
      " And more text. And more text. And more text. And more text. And more \n",
      " text. Oh, how boring typing this stuff. But not as boring as watching \n",
      " paint dry. And more text. And more text. And more text. And more text. \n",
      " Boring.  More, a little more text. The end, and just as well. \n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"sample.pdf\")\n",
    "first_page = reader.pages[0]\n",
    "second_page = reader.pages[1]\n",
    "print(first_page.extract_text() + '\\n' + second_page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run 4 times !!\n"
     ]
    }
   ],
   "source": [
    "lower_corpus = corpus.lower()\n",
    "print(lower_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to finalize the demo corpus which will be used for this notebook  should be done soon  it should be done by the ending of this month but will it this notebook has been run  times\n"
     ]
    }
   ],
   "source": [
    "remove_digits = re.sub(r'\\d+','',lower_corpus)\n",
    "remove_punctuation = remove_digits.translate(str.maketrans('','',string.punctuation))\n",
    "removed_corpus = remove_punctuation.strip()\n",
    "\n",
    "print(removed_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'to', 'finalize', 'the', 'demo', 'corpus', 'which', 'will', 'be', 'used', 'for', 'this', 'notebook', 'should', 'be', 'done', 'soon', 'it', 'should', 'be', 'done', 'by', 'the', 'ending', 'of', 'this', 'month', 'but', 'will', 'it', 'this', 'notebook', 'has', 'been', 'run', 'times']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(removed_corpus)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'finalize', 'demo', 'corpus', 'used', 'notebook', 'done', 'soon', 'done', 'ending', 'month', 'notebook', 'run', 'times']\n"
     ]
    }
   ],
   "source": [
    "no_stops = [word for word in tokens if word not in stop_words]\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'final', 'demo', 'corpu', 'use', 'notebook', 'done', 'soon', 'done', 'end', 'month', 'notebook', 'run', 'time']\n"
     ]
    }
   ],
   "source": [
    "corpus_stems = [stem.stem(word) for word in no_stops]\n",
    "print(corpus_stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatize = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'finalize', 'demo', 'corpus', 'used', 'notebook', 'done', 'soon', 'done', 'ending', 'month', 'notebook', 'run', 'time']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_corpus = [lemmatize.lemmatize(word) for word in no_stops]\n",
    "print(lemmatized_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
